{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss comparison (DA vs. weighted particles)\n",
    "Given a regular radial scan performed with Sixtrack, we try different distributions and compare the lost amount of beam.\n",
    "\n",
    "## Set correct working directory and install libraries in SWAN instance\n",
    "(since SWAN generates a new instance of the notebook in another empty directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working in the right path\n",
    "%cd /eos/project/d/da-and-diffusion-studies/DA_Studies/Simulations/Models/da_sixtrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install --user tqdm pynverse\n",
    "!export PYTHONPATH=$CERNBOX_HOME/.local/lib/python3.7/site-packages:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this \"presentation\" only! As some plotting parts execute a np.log10(0)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from numba import njit, prange\n",
    "\n",
    "# Personal libraries\n",
    "#import sixtrackwrap_light as sx\n",
    "import sixtrackwrap_light as sx\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "from math import gcd\n",
    "\n",
    "from scipy.special import lambertw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"data/\"\n",
    "engine = sx.radial_scanner.load_values(savepath + \"big_scan.pkl\")\n",
    "\n",
    "min_turns = engine.min_time\n",
    "max_turns = engine.max_time\n",
    "n_turn_samples = 500\n",
    "\n",
    "turn_sampling = np.linspace(min_turns, max_turns, n_turn_samples, dtype=np.int_)[::-1]\n",
    "\n",
    "d_r = engine.dr\n",
    "starting_step = engine.starting_step\n",
    "\n",
    "# BASELINE COMPUTING\n",
    "baseline_samples = 33\n",
    "baseline_total_samples = baseline_samples ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, baseline_samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "theta1_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "theta2_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "d_theta1 = theta1_values[1] - theta1_values[0]\n",
    "d_theta2 = theta2_values[1] - theta2_values[0]\n",
    "\n",
    "alpha_mesh, theta1_mesh, theta2_mesh = np.meshgrid(alpha_values, theta1_values, theta2_values, indexing='ij')\n",
    "\n",
    "alpha_flat = alpha_mesh.flatten()\n",
    "theta1_flat = theta1_mesh.flatten()\n",
    "theta2_flat = theta2_mesh.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Colormap for roughly visualize all the samples (regardless of the angle)\n",
    "Here we just observe all the gathered radial samples \"as a bunch\".\n",
    "\n",
    "I choose a logarithmic visualization of the stability value in order to better visualize the variation of the number of stable turns (white means absence of data, i.e. the particle was not simulated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320fbc7e23a64c1ca95bdfd0f61e8f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlidel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log10\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "cmap = ax1.imshow(np.log10(engine.steps), aspect=\"auto\", extent=(engine.starting_step, engine.starting_step + engine.dr * len(engine.steps[0]),0,len(engine.steps)))\n",
    "ax1.set_ylabel(\"Radial sample number\")\n",
    "ax1.set_xlabel(\"Radial distance [normalized Sigma units]\")\n",
    "cbar = plt.colorbar(cmap)\n",
    "cbar.ax.set_ylabel(\"Number of stable turns $\\\\left[\\\\log_{10}(N_{turns})\\\\right]$\")\n",
    "ax1.set_title(\"Heatmap view of the radial scans\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and visualizing 3D samples of DA!\n",
    "\n",
    "With this tool, you can (somewhat) visualize the angular dependencies of DA by moving the $\\theta_1$ and $\\theta_2$ sliders and setting up 3D samples of different dimension (the resulting sample is sample_size ** 3 big).\n",
    "\n",
    "What you will then visualize is the evolution of DA with the number of turns, considering different $\\alpha$ angles ($\\alpha$ indicates the central angle of the considered sample).\n",
    "\n",
    "**N.B.: the plotting process requires time, so after moving the sliders you will need to wait a little!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5290a4663151471c81242389df8d8425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c56db35927b4f61a9354a40706dc313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Size of the cubic sample'), IntSlider(value=2, continuous_update=False, max=29, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7aae8f42d34c80990fb8e080188e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "norm = matplotlib.colors.Normalize(vmin=np.log10(turn_sampling[-1]), vmax=np.log10(turn_sampling[0]))\n",
    "fig.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap), label='Number of stable turns considered\\n$[\\\\log_{10}(N_{turns})]$')\n",
    "\n",
    "radiuses = engine.extract_DA(turn_sampling)\n",
    "radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))\n",
    "\n",
    "@njit\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "@njit\n",
    "def take_sample(array, value, size):\n",
    "    assert size % 2 == 0\n",
    "    array = np.asarray(array)\n",
    "    idx = find_nearest(array, value)\n",
    "    if idx < size:\n",
    "        return 0, size\n",
    "    elif idx >= len(array) - size:\n",
    "        return len(array) - size, len(array)\n",
    "    else:\n",
    "        return idx - size // 2, idx + size // 2\n",
    "\n",
    "def update1(sample_size, th1, th2):\n",
    "    th1 *= np.pi\n",
    "    th2 *= np.pi\n",
    "    y_values = np.empty((len(range(sample_size, len(alpha_preliminary_values))), len(turn_sampling)))\n",
    "    x_values = np.empty((len(range(sample_size, len(alpha_preliminary_values)))))\n",
    "    for i, a_max in enumerate(range(sample_size, len(alpha_preliminary_values))):\n",
    "        a_min = a_max - sample_size\n",
    "        \n",
    "        th1_min, th1_max = take_sample(theta1_values, th1, sample_size)\n",
    "        th2_min, th2_max = take_sample(theta2_values, th2, sample_size)\n",
    "        alpha_sample = alpha_preliminary_values[a_min : a_max]\n",
    "        theta1_sample = theta1_values[th1_min : th1_max]\n",
    "        theta2_sample = theta1_values[th2_min : th2_max]\n",
    "\n",
    "        a_mid = (alpha_values[a_min] + alpha_values[a_max]) / 2\n",
    "        \n",
    "        mod_radiuses = np.power(radiuses, 4)[a_min : a_max, th1_min : th1_max, th2_min : th2_max]\n",
    "        \n",
    "        mod_radiuses = integrate.simps(mod_radiuses, x=theta1_sample, axis=1)\n",
    "        mod_radiuses = integrate.simps(mod_radiuses, x=theta2_sample, axis=1)\n",
    "        mod_radiuses = integrate.simps(mod_radiuses, x=alpha_sample, axis=0)\n",
    "\n",
    "        DA = (\n",
    "            np.power(\n",
    "                mod_radiuses / (\n",
    "                    (alpha_sample[-1] - alpha_sample[0]) \n",
    "                    * (theta1_sample[-1] - theta1_sample[0]) \n",
    "                    * (theta2_sample[-1] - theta2_sample[0])),\n",
    "                1/4\n",
    "            )\n",
    "        )\n",
    "        y_values[i] = DA\n",
    "        x_values[i] = a_mid\n",
    "    y_values = np.asarray(y_values)\n",
    "    y_values = y_values.transpose()\n",
    "    x_values = np.asarray(x_values)\n",
    "    ax.clear()\n",
    "    for i in range(y_values.shape[0]):\n",
    "        value = np.log10(turn_sampling[i] - turn_sampling[-1]) / np.log10(turn_sampling[0] - turn_sampling[-1])\n",
    "        ax.plot(x_values, y_values[i], c=cmap(value))\n",
    "    ax.set_xlabel(\"Central $\\\\alpha$ angle\")\n",
    "    ax.set_ylabel(\"Measured $DA$ in sample\")\n",
    "    ax.set_title(\"DA evolution over $\\\\alpha$ for a moving average of ${}^3$ elements (total is ${}^3$)\\nCentral $\\\\theta$ angles: $(\\\\theta_1 = {:.2f}\\\\pi, \\\\theta_2 = {:.2f}\\\\pi)$\".format(sample_size, baseline_samples, th1/np.pi, th2/np.pi, baseline_samples))\n",
    "    ax.set_ylim(np.min(radiuses), np.max(radiuses))\n",
    "    ax.set_xlim(0.0, np.pi / 2.0)\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        ticker.FuncFormatter(\n",
    "            lambda x, pos: (\"$\\\\frac{{{}}}{{{}}}$\".format(int(x/(np.pi/8)) // gcd(8, int(x/(np.pi/8))), 8 // gcd(8, int(x/(np.pi/8)))) if x != 0 else \"0\") + \"$\\\\pi$\"\n",
    "        )\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=np.pi/8))\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "a=widgets.IntSlider(value=2, min=2, max=baseline_samples - 4, step=2, continuous_update=False)\n",
    "b=widgets.FloatSlider(value=1, min=0, max=2 + 0.01, step=0.01, continuous_update=False)\n",
    "c=widgets.FloatSlider(value=1, min=0, max=2 + 0.01, step=0.01, continuous_update=False)\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Size of the cubic sample\"), a,\n",
    "    widgets.Label(\"$\\\\theta_1$ value $[\\\\pi$ units$]$\"), b,\n",
    "    widgets.Label(\"$\\\\theta_2$ value $[\\\\pi$ units$]$\"), c])\n",
    "    \n",
    "out = widgets.interactive_output(\n",
    "    update1,\n",
    "    {\"sample_size\":a, \"th1\":b, \"th2\":c}\n",
    ")\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for loss comparison analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = engine.extract_DA(turn_sampling)\n",
    "radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = []\n",
    "\n",
    "mod_radiuses = radiuses.copy()\n",
    "mod_radiuses = np.power(radiuses, 4)\n",
    "mod_radiuses1 = integrate.simps(mod_radiuses, x=theta1_values, axis=1)\n",
    "mod_radiuses2 = integrate.simps(mod_radiuses1, x=theta2_values, axis=1)\n",
    "mod_radiuses3 = integrate.simps(mod_radiuses2, x=alpha_preliminary_values, axis=0)\n",
    "\n",
    "for i in range(len(turn_sampling)):\n",
    "    DA.append(\n",
    "        np.power(\n",
    "            mod_radiuses3[i] / (2 * theta1_values[-1] * theta2_values[-1]),\n",
    "            1/4\n",
    "        )\n",
    "    )\n",
    "\n",
    "DA = np.asarray(DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_sampling = np.concatenate((turn_sampling,[0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the error on the DA loss computed right now?\n",
    "\n",
    "1. Consider all the radiuses sampled.\n",
    "2. Compute the DA value.\n",
    "3. For every radius sampled, compute the difference from the DA value.\n",
    "4. The absolute value of the average of all these differences is considered as error.\n",
    "\n",
    "(I tried using the Standard Deviation of the radiuses distribution, but it ended up being 10% of the DA itself, so we \"need\" somehow a smaller error estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform distribution case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_from_DA(da_list, da_cut):\n",
    "    temp = np.pi ** 2 / 2 * np.power(da_list, 4)\n",
    "    return np.concatenate((temp, [np.pi ** 2 / 2 * np.power(da_cut, 4)]))\n",
    "\n",
    "values = loss_from_DA(DA, 26.0)\n",
    "values /= values[-1]\n",
    "values[-20:]\n",
    "\n",
    "# Error computing\n",
    "\n",
    "values1 = loss_from_DA(DA - np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), 26)\n",
    "values1 /= values1[-1]\n",
    "\n",
    "values2 = loss_from_DA(DA + np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), 26)\n",
    "values2 /= values2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.assign_weights(\n",
    "    sx.assign_uniform_distribution()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57d2348a57c4320ae03c1e1e570b49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Uniform beam (Cutting Point at $DA=26.0$)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_values = engine.compute_loss(turn_sampling, 26)\n",
    "real_values\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(axis_sampling, values, label=\"Values from DA\")\n",
    "ax3.fill_between(axis_sampling, values1, values2, label=\"Values from DA - error\", color=\"C0\", alpha=0.4)\n",
    "ax3.plot(axis_sampling, real_values, label=\"Values from weights\")\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"Active beam\")\n",
    "ax3.set_title(\"Uniform beam (Cutting Point at $DA=26.0$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian with slider available for $\\sigma$\n",
    "\n",
    "With the slider it is possible to regulate the $\\sigma$ value of the 4D gaussian beam distribution.\n",
    "\n",
    "It is possible to observe how extreme values for $\\sigma$ strongly changes the two loss behaviours.\n",
    "\n",
    "**N.B.: Place the slider at the desired position and then press the button!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5655d496d4f743a6a810449824e7505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491307db6124403fa3786cfdce0c0e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=15.0, description='sigma', max=30.0, min=1.0, step=0.5), Button(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update2(sigma)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "def update2(sigma):\n",
    "    ax2.clear()\n",
    "    # Cursed Sanity Check\n",
    "    def loss_from_DA(DA_list, DA_max):\n",
    "        temp = - np.exp(- ((DA_list / sigma) ** 2) / 2) * (DA_list ** 2 + 2 * sigma ** 2) + 2 * sigma ** 2\n",
    "        return np.concatenate((temp, [- np.exp(- ((DA_max / sigma) ** 2) / 2) * (DA_max ** 2 + 2 * sigma ** 2) + 2 * sigma ** 2]))\n",
    "\n",
    "    values = loss_from_DA(DA, 26.0)\n",
    "    values /= values[-1]\n",
    "    values[-20:]\n",
    "\n",
    "    # Error computing\n",
    "    \n",
    "    values1 = loss_from_DA(DA - np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), 26)\n",
    "    values1 /= values1[-1]\n",
    "\n",
    "    values2 = loss_from_DA(DA + np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), 26)\n",
    "    values2 /= values2[-1]\n",
    "\n",
    "    engine.assign_weights(\n",
    "        sx.assign_symmetric_gaussian(sigma)\n",
    "    )\n",
    "\n",
    "    real_values = engine.compute_loss(turn_sampling, 26)\n",
    "    ax2.plot(axis_sampling, values, label=\"Values from DA\")\n",
    "    ax2.fill_between(axis_sampling, values1, values2, color=\"C0\", alpha=0.4)\n",
    "    ax2.plot(axis_sampling, real_values, label=\"Values from weights\")\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel(\"$N$ turns\")\n",
    "    ax2.set_ylabel(\"Active beam\")\n",
    "    ax2.set_title(\"Symmetric gaussian beam\\n($\\\\sigma = {}$, cutting Point at $DA=26.0$)\".format(sigma))\n",
    "    plt.tight_layout()\n",
    "\n",
    "widgets.interact_manual(update2, sigma=widgets.FloatSlider(value=15, min=1, max=30, step=0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A contour plot for analyzing the N turns / Sigma relation in the loss difference between real values and DA-based values for a symmetric gaussian distribution\n",
    "\n",
    "## Data computation (this takes a long time!)\n",
    "Here we compute the loss for many different values of sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a71b760f244b3f92b2055485faf0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sigma_samples = 100\n",
    "sigma_list = np.linspace(2.0, 30, sigma_samples)\n",
    "\n",
    "r_values = np.empty((sigma_samples, len(axis_sampling)))\n",
    "DA_values = np.empty((sigma_samples, len(axis_sampling)))\n",
    "\n",
    "@njit\n",
    "def loss_from_DA(DA_list, DA_max, sigma):\n",
    "        temp = - np.exp(- ((DA_list / sigma) ** 2) / 2) * (DA_list ** 2 + 2 * sigma ** 2) + 2 * sigma ** 2\n",
    "        temp = np.concatenate((temp, np.array([- np.exp(- ((DA_max / sigma) ** 2) / 2) * (DA_max ** 2 + 2 * sigma ** 2) + 2 * sigma ** 2])))\n",
    "        return temp\n",
    "    \n",
    "    \n",
    "for i, sigma in tqdm(enumerate(sigma_list), total=len(sigma_list)):\n",
    "    values = loss_from_DA(DA, 26.0, sigma)\n",
    "    values /= values[-1]\n",
    "    DA_values[i] = values\n",
    "    engine.assign_weights(\n",
    "        sx.assign_symmetric_gaussian(sigma)\n",
    "    )\n",
    "\n",
    "    real_values = engine.compute_loss(turn_sampling, 26)\n",
    "    r_values[i] = real_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "### Two colormaps for basic comparison\n",
    "Here we visualize how the relative loss changes depending on the $\\sigma$ value of the 4D gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67330c85bb7346c7b02985f52489fb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f4e2a696a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig4, axs4 = plt.subplots(ncols=2)\n",
    "\n",
    "global_min = min(np.min(r_values), np.min(DA_values))\n",
    "\n",
    "axs4[0].imshow(r_values[:,::-1], aspect='auto', extent=(axis_sampling[-1], axis_sampling[0], sigma_list[0], sigma_list[-1]), vmin=global_min, vmax=1)\n",
    "axs4[0].set_xlabel(\"$N$ turns\")\n",
    "axs4[0].set_ylabel(\"$\\\\sigma$ value\")\n",
    "axs4[0].set_title(\"Loss from actual lost particles\")\n",
    "\n",
    "im = axs4[1].imshow(DA_values[:,::-1], aspect='auto', extent=(axis_sampling[-1], axis_sampling[0], sigma_list[0], sigma_list[-1]), vmin=global_min, vmax=1)\n",
    "axs4[1].set_xlabel(\"$N$ turns\")\n",
    "axs4[1].set_ylabel(\"$\\\\sigma$ value\")\n",
    "axs4[1].set_title(\"Loss from DA extrapolation\")\n",
    "\n",
    "fig4.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig4.add_axes([0.90, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, label=\"Relative loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A contour plot for the difference evolution\n",
    "\n",
    "Here we visualize the evolution of the relative error value:\n",
    "\n",
    "$$ \\frac{|\\text{Loss}_{\\text{true}}-\\text{Loss}_{\\text{DA}}|}{\\text{Loss}_{\\text{true}}}$$\n",
    "\n",
    "**N.B.** for extremely low $\\sigma$ values we degenerate to a near-zero error since we register almost no loss at all with the scanning we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ee9318c0844efe82740dd10b2cd7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Relative difference between real loss and DA loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig5, ax5 = plt.subplots()\n",
    "skip = -50\n",
    "XX, YY = np.meshgrid(axis_sampling, sigma_list)\n",
    "img = ax5.contourf(XX[:,:skip], YY[:,:skip], (np.absolute(DA_values - r_values)/r_values)[:,:skip], levels=10)\n",
    "fig5.colorbar(img, label=\"Relative error\")\n",
    "ax5.set_xlabel(\"$N$ turns\")\n",
    "ax5.set_ylabel(\"$\\\\sigma$ value\")\n",
    "ax5.set_title(\"Relative difference between real loss and DA loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
