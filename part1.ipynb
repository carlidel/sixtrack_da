{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Baseline and Standard Integral\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from tqdm import tqdm\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "# Personal libraries\n",
    "import sixtrackwrap as sx\n",
    "\n",
    "from parameters import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_b = {}\n",
    "error_b = {}\n",
    "\n",
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, baseline_samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "theta1_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "theta2_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "d_theta1 = theta1_values[1] - theta1_values[0]\n",
    "d_theta2 = theta2_values[1] - theta2_values[0]\n",
    "\n",
    "alpha_mesh, theta1_mesh, theta2_mesh = np.meshgrid(alpha_values, theta1_values, theta2_values, indexing='ij')\n",
    "\n",
    "alpha_flat = alpha_mesh.flatten()\n",
    "theta1_flat = theta1_mesh.flatten()\n",
    "theta2_flat = theta2_mesh.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active radiuses: 35937 / 35937\n",
      "Sample size per active radius: 1\n",
      "Expected execution time for step: nan\n",
      "Elapsed time for whole iteration: 27.73\n",
      "Time per single iteration: 1.543267069049473e-05\n",
      "r: 15.0 . Turns to do: 50 . Min found: 50\n",
      "Active radiuses: 35937 / 35937\n",
      "Sample size per active radius: 1\n",
      "Expected execution time for step: 27.73\n",
      "Elapsed time for whole iteration: 27.64\n",
      "Time per single iteration: 1.538009507152484e-05\n",
      "r: 20.0 . Turns to do: 50 . Min found: 35\n",
      "Active radiuses: 35937 / 35937\n",
      "Sample size per active radius: 1\n",
      "Expected execution time for step: 27.64\n",
      "Elapsed time for whole iteration: 27.40\n",
      "Time per single iteration: 1.524844770555979e-05\n",
      "r: 25.0 . Turns to do: 50 . Min found: 4\n",
      "Active radiuses: 33831 / 35937\n",
      "Sample size per active radius: 1\n",
      "Expected execution time for step: 25.79\n",
      "Elapsed time for whole iteration: 29.54\n",
      "Time per single iteration: 1.7465159174982358e-05\n",
      "r: 30.0 . Turns to do: 50 . Min found: 0\n",
      "Active radiuses: 20159 / 35937\n",
      "Sample size per active radius: 1\n",
      "Expected execution time for step: 17.60\n",
      "Elapsed time for whole iteration: 17.96\n",
      "Time per single iteration: 1.78179461081188e-05\n",
      "r: 35.0 . Turns to do: 50 . Min found: 0\n",
      "Active radiuses: 4416 / 35937\n",
      "Sample size per active radius: 1\n",
      "Expected execution time for step: 3.93\n",
      "Elapsed time for whole iteration: 4.04\n",
      "Time per single iteration: 1.8281146236087963e-05\n",
      "r: 40.0 . Turns to do: 50 . Min found: 0\n",
      "Active radiuses: 581 / 35937\n",
      "Sample size per active radius: 4\n",
      "Expected execution time for step: 2.12\n",
      "Elapsed time for whole iteration: 1.99\n",
      "Time per single iteration: 1.7087082033928825e-05\n",
      "r: 60.0 . Turns to do: 4 . Min found: 0\n",
      "TOTAL ELAPSED TIME IN SECONDS: 136.29\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# Data generation\n",
    "engine = sx.radial_scanner(alpha_flat, theta1_flat, theta2_flat, d_r, starting_step=starting_step)\n",
    "\n",
    "engine.scan(max_turns, min_turns, batch_size=batch_size)\n",
    "\n",
    "radiuses = engine.extract_DA(turn_sampling)\n",
    "radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))\n",
    "\n",
    "data_b = radiuses\n",
    "\n",
    "elapsed_time_engine = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "radiuses = data_b\n",
    "# Computing DA\n",
    "DA = []\n",
    "error_list = []\n",
    "mod_radiuses = radiuses.copy()\n",
    "mod_radiuses = np.power(radiuses, 4)\n",
    "\n",
    "mod_radiuses1 = integrate.simps(mod_radiuses, x=theta1_values, axis=1)\n",
    "error_radiuses1 = np.absolute(\n",
    "    (mod_radiuses1 - integrate.simps(mod_radiuses[:,::2,:], x=theta1_values[::2], axis=1)) / mod_radiuses1\n",
    ")\n",
    "error_radiuses1 = np.average(error_radiuses1, axis=1)\n",
    "\n",
    "mod_radiuses2 = integrate.simps(mod_radiuses1, x=theta2_values, axis=1)\n",
    "error_radiuses2 = np.absolute(\n",
    "    (mod_radiuses2 - integrate.simps(mod_radiuses1[:,::2], x=theta2_values[::2], axis=1)) / mod_radiuses2\n",
    ")\n",
    "error_radiuses2 += error_radiuses1\n",
    "error_radiuses2 = np.average(error_radiuses2, axis=0)\n",
    "\n",
    "mod_radiuses3 = integrate.simps(mod_radiuses2, x=alpha_preliminary_values, axis=0)\n",
    "error_radiuses3 = np.absolute(\n",
    "    (mod_radiuses3 - integrate.simps(mod_radiuses2[::2], x=alpha_preliminary_values[::2], axis=0)) / mod_radiuses3\n",
    ")\n",
    "error_radiuses3 += error_radiuses2\n",
    "\n",
    "error_raw = mod_radiuses3/ (2 * theta1_values[-1] * theta2_values[-1]) * error_radiuses3\n",
    "error = 0.25 * np.power(mod_radiuses3 / (2 * theta1_values[-1] * theta2_values[-1]), -3/4) * error_raw\n",
    "\n",
    "for i in range(len(turn_sampling)):\n",
    "    DA.append(\n",
    "        np.power(\n",
    "            mod_radiuses3[i] / (2 * theta1_values[-1] * theta2_values[-1]),\n",
    "            1/4\n",
    "        )\n",
    "    )\n",
    "    error_list.append(error[i])\n",
    "DA_b = np.asarray(DA)\n",
    "error_b = np.asarray(error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(savepath + \"data/raw_data_b.pkl\", 'wb') as f:\n",
    "    pickle.dump(data_b, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/DA_b.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_b, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_b.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_b, f, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = data_b.reshape(-1, data_b.shape[-1])\n",
    "    \n",
    "average = np.average(np.power(radiuses, 4), axis=0)\n",
    "error = np.std(np.power(radiuses, 4), axis=0) / np.sqrt(radiuses.shape[0])\n",
    "\n",
    "DA_b_mc = np.power(average, 1/4)\n",
    "error_b_mc = 0.25 * np.power(average, -3/4) * error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(savepath + \"data/DA_b_mc.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_b_mc, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_b_mc.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_b_mc, f, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_1 = {}\n",
    "error_1 = {}\n",
    "base_radiuses = data_b\n",
    "\n",
    "values = [2]\n",
    "while True:\n",
    "    if (baseline_samples - 1) // values[-1] > 4:\n",
    "        values.append(values[-1] * 2)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for i in values:\n",
    "    radiuses = base_radiuses[::i, ::i, ::i]\n",
    "    DA = []\n",
    "    error_list = []\n",
    "    mod_radiuses = radiuses.copy()\n",
    "    mod_radiuses = np.power(radiuses, 4)\n",
    "\n",
    "    mod_radiuses1 = integrate.simps(mod_radiuses, x=theta1_values[::i], axis=1)\n",
    "    error_radiuses1 = np.absolute(\n",
    "        (mod_radiuses1 - integrate.simps(mod_radiuses[:,::2,:], x=theta1_values[::i * 2], axis=1)) / mod_radiuses1\n",
    "    )\n",
    "    error_radiuses1 = np.average(error_radiuses1, axis=1)\n",
    "\n",
    "    mod_radiuses2 = integrate.simps(mod_radiuses1, x=theta2_values[::i], axis=1)\n",
    "    error_radiuses2 = np.absolute(\n",
    "        (mod_radiuses2 - integrate.simps(mod_radiuses1[:,::2], x=theta2_values[::i * 2], axis=1)) / mod_radiuses2\n",
    "    )\n",
    "    error_radiuses2 += error_radiuses1\n",
    "    error_radiuses2 = np.average(error_radiuses2, axis=0)\n",
    "\n",
    "    mod_radiuses3 = integrate.simps(mod_radiuses2, x=alpha_preliminary_values[::i], axis=0)\n",
    "    error_radiuses3 = np.absolute(\n",
    "        (mod_radiuses3 - integrate.simps(mod_radiuses2[::2], x=alpha_preliminary_values[::i * 2], axis=0)) / mod_radiuses3\n",
    "    )\n",
    "    error_radiuses3 += error_radiuses2\n",
    "\n",
    "    error_raw = mod_radiuses3/ (2 * theta1_values[-1] * theta2_values[-1]) * error_radiuses3\n",
    "    error = 0.25 * np.power(mod_radiuses3 / (2 * theta1_values[-1] * theta2_values[-1]), -3/4) * error_raw\n",
    "\n",
    "    for j in range(len(turn_sampling)):\n",
    "        DA.append(\n",
    "            np.power(\n",
    "                mod_radiuses3[j] / (2 * theta1_values[-1] * theta2_values[-1]),\n",
    "                1/4\n",
    "            )\n",
    "        )\n",
    "        error_list.append(error[j])\n",
    "    DA_1[radiuses.shape[0]**3] = np.asarray(DA)\n",
    "    error_1[radiuses.shape[0]**3] = np.asarray(error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(savepath + \"data/DA_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_1, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_1, f, protocol=4)\n",
    "    \n",
    "elapsed_time_processing = time.time() - time_start\n",
    "\n",
    "with open(savepath + \"data/time_1.pkl\", \"wb\") as f:\n",
    "    pickle.dump((elapsed_time_engine, elapsed_time_processing), f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
