{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Average\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from tqdm import tqdm\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "# Personal libraries\n",
    "import sixtrackwrap as sx\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active radiuses: 1025 / 1025\n",
      "Sample size per active radius: 20\n",
      "Expected execution time for step: nan\n",
      "Elapsed time for whole iteration: 3.42\n",
      "Time per single iteration: 1.6697997581668015e-05\n",
      "r: 29.0 . Turns to do: 10 . Min found: 2\n",
      "Active radiuses: 1025 / 1025\n",
      "Sample size per active radius: 20\n",
      "Expected execution time for step: 3.42\n",
      "Elapsed time for whole iteration: 2.96\n",
      "Time per single iteration: 1.4459459956099348e-05\n",
      "r: 49.0 . Turns to do: 3 . Min found: 0\n",
      "Active radiuses: 472 / 1025\n",
      "Sample size per active radius: 43\n",
      "Expected execution time for step: 0.88\n",
      "Elapsed time for whole iteration: 0.76\n",
      "Time per single iteration: 1.2441018833435564e-05\n",
      "r: 92.0 . Turns to do: 0 . Min found: 0\n",
      "TOTAL ELAPSED TIME IN SECONDS: 7.14\n"
     ]
    }
   ],
   "source": [
    "error_2 = {}\n",
    "DA_2 = {}\n",
    "raw_error_2 = {}\n",
    "DA_5 = {}\n",
    "error_5 = {}\n",
    "\n",
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "\n",
    "# Extracting the radiuses with theta1 = theta2 = 0.0\n",
    "\n",
    "engine = sx.radial_scanner(\n",
    "    alpha_values, \n",
    "    np.zeros(alpha_values.shape),\n",
    "    np.zeros(alpha_values.shape),\n",
    "    d_r,\n",
    "    starting_step=starting_step\n",
    ")\n",
    "engine.scan(turn_sampling[0], turn_sampling[-1], batch_size=batch_size)\n",
    "all_radiuses = engine.extract_DA(turn_sampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D simple integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "skips = [1]\n",
    "while True:\n",
    "    if (samples - 1) // skips[-1] > 4:\n",
    "        skips.append(skips[-1] * 2)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for i in skips:\n",
    "    alpha = alpha_preliminary_values[::i]\n",
    "    cutted_radiuses = all_radiuses[::i]\n",
    "    value = integrate.simps(cutted_radiuses ** 2, alpha, axis=0)\n",
    "    less_value = integrate.simps(cutted_radiuses[::2] ** 2, alpha[::2], axis=0)\n",
    "    uncertainty = np.abs((value - less_value))\n",
    "\n",
    "    DA = np.sqrt(value / 2)\n",
    "    uncertainty = 0.5 * np.power(value / 2, -0.5) * uncertainty\n",
    "    DA_5[cutted_radiuses.shape] = np.asarray(DA)\n",
    "    error_5[cutted_radiuses.shape] = uncertainty "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual angular averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "indexes = []\n",
    "raw_values = []\n",
    "refined_values = []\n",
    "    \n",
    "for i in tqdm(range(len(turn_sampling))):\n",
    "    radiuses = all_radiuses[:, i]\n",
    "\n",
    "    r, a, th1, th2 = sx.full_track_particles(\n",
    "        radiuses,\n",
    "        alpha_values,\n",
    "        np.zeros(alpha_values.shape),\n",
    "        np.zeros(alpha_values.shape),\n",
    "        turn_sampling[i])\n",
    "\n",
    "    count_matrix, avg_matrix, _ = sx.accumulate_and_return(r, a, th1, th2, n_subdivisions)\n",
    "    _, _, result_total, validity_total = sx.recursive_accumulation(count_matrix, avg_matrix)\n",
    "    \n",
    "    values.append(result_total)\n",
    "    indexes.append(np.argmax(validity_total, axis=0))\n",
    "    refined_values.append([result_total[indexes[-1][i]][i] for i in range(len(indexes[-1]))])\n",
    "    raw_values.append(np.average(np.power(r, 4), axis=1))\n",
    "        \n",
    "steps = [1]\n",
    "while True:\n",
    "    if (values[0][0].shape[0] - 1) / steps[-1] > 4:\n",
    "        steps.append(steps[-1] * 2)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "for jump in steps:\n",
    "    DA = []\n",
    "    error = []\n",
    "    DA_mc = []\n",
    "    raw_error_mc = []\n",
    "    error_mc = []\n",
    "    for i in range(len(turn_sampling)):\n",
    "        DA.append(np.power(integrate.simps(refined_values[i][::jump], alpha_preliminary_values[::jump]) * 0.5, 1/4))\n",
    "        temp = np.power(integrate.simps(refined_values[i][::jump * 2], alpha_preliminary_values[::jump * 2]) * 0.5, 1/4)\n",
    "        error.append(np.absolute(DA[-1] - temp))\n",
    "\n",
    "        DA_mc.append(np.power(np.average(refined_values[i][::jump]), 1/4))\n",
    "        raw_error_mc.append(np.std(refined_values[i][::jump]))\n",
    "        error_mc.append(0.25 * np.power(DA_mc[-1], -3) * np.std(values[i][::jump]) / np.sqrt(np.size(values[i][::jump])))\n",
    "\n",
    "    DA_2[( len(refined_values[i][::jump]), \"refined\", \"int\")] = DA\n",
    "    error_2[( len(refined_values[i][::jump]), \"refined\", \"int\")] = error\n",
    "    DA_2[( len(refined_values[i][::jump]), \"refined\", \"mc\")] = DA_mc\n",
    "    error_2[( len(refined_values[i][::jump]), \"refined\", \"mc\")] = error_mc\n",
    "    raw_error_2[( len(refined_values[i][::jump]), \"refined\", \"mc\")] = raw_error_mc\n",
    "\n",
    "    DA = []\n",
    "    error = []\n",
    "    DA_mc = []\n",
    "    raw_error_mc = []\n",
    "    error_mc = []\n",
    "    for i in range(len(turn_sampling)):\n",
    "        DA.append(np.power(integrate.simps(raw_values[i][::jump], alpha_preliminary_values[::jump]) * 0.5, 1/4))\n",
    "        temp = np.power(integrate.simps(raw_values[i][::jump * 2], alpha_preliminary_values[::jump * 2]) * 0.5, 1/4)\n",
    "        error.append(np.absolute(DA[-1] - temp))\n",
    "\n",
    "        DA_mc.append(np.power(np.average(raw_values[i][::jump]), 1/4))\n",
    "        raw_error_mc.append(np.std(raw_values[i][::jump]))\n",
    "        error_mc.append(0.25 * np.power(DA_mc[-1], -3) * np.std(values[i][::jump]) / np.sqrt(np.size(values[i][::jump])))\n",
    "\n",
    "    DA_2[( len(raw_values[i][::jump]), \"raw\", \"int\")] = DA\n",
    "    error_2[( len(raw_values[i][::jump]), \"raw\", \"int\")] = error\n",
    "    DA_2[( len(raw_values[i][::jump]), \"raw\", \"mc\")] = DA_mc\n",
    "    error_2[( len(raw_values[i][::jump]), \"raw\", \"mc\")] = error_mc\n",
    "    raw_error_2[( len(raw_values[i][::jump]), \"raw\", \"mc\")] = raw_error_mc\n",
    "\n",
    "    for j in range(len(values[0])):\n",
    "        DA = []\n",
    "        error = []\n",
    "        DA_mc = []\n",
    "        raw_error_mc = []\n",
    "        error_mc = []\n",
    "        for i in range(len(turn_sampling)):\n",
    "            DA.append(np.power(integrate.simps(values[i][j][::jump], alpha_preliminary_values[::jump]) * 0.5, 1/4))\n",
    "            temp = np.power(integrate.simps(values[i][j][::jump * 2], alpha_preliminary_values[::jump * 2]) * 0.5, 1/4)\n",
    "            error.append(np.absolute(DA[-1] - temp))\n",
    "\n",
    "            DA_mc.append(np.power(np.average(values[i][j][::jump]), 1/4))\n",
    "            raw_error_mc.append(np.std(values[i][j][::jump]))\n",
    "            error_mc.append(0.25 * np.power(DA_mc[-1], -3) * np.std(values[i][j][::jump]) / np.sqrt(np.size(values[i][j][::jump])))\n",
    "\n",
    "        DA_2[( len(values[i][j][::jump]), 2 ** (j), \"int\")] = DA\n",
    "        error_2[( len(values[i][j][::jump]), 2 ** (j), \"int\")] = error\n",
    "        DA_2[( len(values[i][j][::jump]), 2 ** (j), \"mc\")] = DA_mc\n",
    "        error_2[( len(values[i][j][::jump]), 2 ** (j), \"mc\")] = error_mc\n",
    "        raw_error_2[( len(values[i][j][::jump]), 2 ** (j), \"mc\")] = raw_error_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(savepath + \"data/DA_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_2, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_2, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/raw_error_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(raw_error_2, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/DA_5.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_5, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_5.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_5, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
