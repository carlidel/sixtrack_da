{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General DA fittings and Fokker-Planck comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we are in the SWAN notebook system, you need to execute this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /eos/project/d/da-and-diffusion-studies/DA_Studies/Simulations/Models/da_sixtrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For having no warnings in the visualization (USE ONLY IF YOU ARE NOT A DEVELOPER!)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from numba import njit, prange\n",
    "\n",
    "# Personal libraries\n",
    "#import sixtrackwrap_light as sx\n",
    "import sixtrackwrap as sx\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "from math import gcd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import lambertw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and setup original DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"data/\"\n",
    "engine = sx.radial_scanner.load_values(savepath + \"big_scan.pkl\")\n",
    "\n",
    "min_turns = engine.min_time\n",
    "max_turns = engine.max_time\n",
    "n_turn_samples = 500\n",
    "\n",
    "turn_sampling = np.linspace(min_turns, max_turns, n_turn_samples, dtype=np.int_)[::-1]\n",
    "\n",
    "d_r = engine.dr\n",
    "starting_step = engine.starting_step\n",
    "\n",
    "# BASELINE COMPUTING\n",
    "baseline_samples = 33\n",
    "baseline_total_samples = baseline_samples ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, baseline_samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "theta1_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "theta2_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "d_theta1 = theta1_values[1] - theta1_values[0]\n",
    "d_theta2 = theta2_values[1] - theta2_values[0]\n",
    "\n",
    "alpha_mesh, theta1_mesh, theta2_mesh = np.meshgrid(alpha_values, theta1_values, theta2_values, indexing='ij')\n",
    "\n",
    "alpha_flat = alpha_mesh.flatten()\n",
    "theta1_flat = theta1_mesh.flatten()\n",
    "theta2_flat = theta2_mesh.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = engine.extract_DA(turn_sampling)\n",
    "radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = []\n",
    "\n",
    "mod_radiuses = radiuses.copy()\n",
    "mod_radiuses = np.power(radiuses, 4)\n",
    "mod_radiuses1 = integrate.simps(mod_radiuses, x=theta1_values, axis=1)\n",
    "mod_radiuses2 = integrate.simps(mod_radiuses1, x=theta2_values, axis=1)\n",
    "mod_radiuses3 = integrate.simps(mod_radiuses2, x=alpha_preliminary_values, axis=0)\n",
    "\n",
    "for i in range(len(turn_sampling)):\n",
    "    DA.append(\n",
    "        np.power(\n",
    "            mod_radiuses3[i] / (2 * theta1_values[-1] * theta2_values[-1]),\n",
    "            1/4\n",
    "        )\n",
    "    )\n",
    "\n",
    "DA = np.asarray(DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_sampling = np.concatenate((turn_sampling,[0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare inverse functions for obtaining DA from loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynverse import inversefunc\n",
    "\n",
    "# Uniform 4D distribution\n",
    "\n",
    "@njit\n",
    "def uniform_loss(DA, DA0):\n",
    "    return (DA ** 4 / DA0 ** 4)\n",
    "\n",
    "@njit\n",
    "def DA_from_unifom_loss(loss, DA0):\n",
    "    return np.power((loss * DA0 ** 4), 1/4)\n",
    "\n",
    "# Symmetric 4D gaussian\n",
    "\n",
    "@njit\n",
    "def symmetric_gaussian_loss(DA, sigma, DA0):\n",
    "    baseline = - np.exp(- 0.5 * (DA0 / sigma) ** 2) * (DA0 ** 2 + 2 * sigma ** 2) + 2 * sigma ** 2\n",
    "    return (- np.exp(- 0.5 * (DA / sigma) ** 2) * (DA ** 2 + 2 * sigma ** 2) + 2 * sigma ** 2) / baseline\n",
    "\n",
    "\n",
    "def DA_from_symmetric_gaussian_loss(loss, sigma, DA0):\n",
    "    func = inversefunc(\n",
    "        lambda x: symmetric_gaussian_loss(x, sigma, DA0),\n",
    "        domain=0.0,\n",
    "        open_domain=[False, True]\n",
    "    )\n",
    "    return func(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Fitting Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "$$D(N) = \\rho_\\ast \\left(\\frac{\\kappa}{2e}\\right)^\\kappa \\frac{1}{\\ln^\\kappa\\frac{N}{N_0}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def model_2(x, rho, n0, k):\n",
    "    return rho * np.power(k / (2 * np.exp(1)), k) / (np.power(np.log(x / n0), k))\n",
    "\n",
    "\n",
    "def explore_k_model_2(turns, da, k_min, k_max, n_samples):\n",
    "    ks = np.linspace(k_min, k_max, n_samples)\n",
    "    pars = []\n",
    "    errs = []\n",
    "    co_pars = []\n",
    "    for k in tqdm(ks):\n",
    "        par, co_par = curve_fit(\n",
    "            lambda x, a, b : model_2(x, a, b, k),\n",
    "            turns,\n",
    "            da,\n",
    "            bounds=([0, 0.00001],[np.inf, turns[-1]-0.0001])\n",
    "        )\n",
    "        pars.append(par)\n",
    "        co_pars.append(co_par)\n",
    "        errs.append(np.sum(np.power(DA - model_2(turn_sampling, par[0], par[1], k), 2)[:]))\n",
    "    return np.asarray(pars), np.asarray(errs), np.asarray(co_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4\n",
    "\n",
    "$$D(N)=\\rho_{*} \\times \\frac{1}{\\left[-2 \\mathrm{e} \\lambda \\mathcal{W}_{-1}\\left(-\\frac{1}{2 \\mathrm{e} \\lambda}\\left(\\frac{\\rho_{\\ast}}{6}\\right)^{1 / \\kappa}\\left(\\frac{8}{7} N\\right)^{-1 /(\\lambda \\kappa)}\\right)\\right]^{\\kappa}}\n",
    "$$\n",
    "\n",
    "(with $\\lambda=0.5$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_4(x, rho, k):\n",
    "    lamb = 0.5\n",
    "    return np.real(\n",
    "        rho\n",
    "        / np.power(-2 * np.exp(1) * lamb * lambertw(- (1 / (2 * np.exp(1) * lamb)) * np.power(rho / 6, 1 / k) * np.power((8/7) * x, -1 / (lamb * k)), -1), k)\n",
    "    )\n",
    "\n",
    "def explore_k_model_4(turns, da, k_min, k_max, n_samples):\n",
    "    ks = np.linspace(k_min, k_max, n_samples)\n",
    "    pars = []\n",
    "    errs = []\n",
    "    co_pars = []\n",
    "    for k in tqdm(ks):\n",
    "        par, co_par = curve_fit(\n",
    "            lambda x, a : model_4(x, a, k),\n",
    "            turns,\n",
    "            da,\n",
    "            bounds=([0.1],[np.inf])\n",
    "        )\n",
    "        pars.append(par)\n",
    "        co_pars.append(co_par)\n",
    "        errs.append(np.sum(np.power(DA - model_4(turn_sampling, par[0], k), 2)[:]))\n",
    "    return np.asarray(pars), np.asarray(errs), np.asarray(co_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize original DA value from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0eea5e35714b9681660e9336307d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$DA(N)$')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(turn_sampling, DA)\n",
    "ax1.set_title(\"Original $DA$ values (LHC on SixTrack)\")\n",
    "ax1.set_xlabel(\"$N$ turns\")\n",
    "ax1.set_ylabel(\"$DA(N)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataframe for storing the fitting data properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (\n",
    "    (\"type\", \"\"),\n",
    "    (\"sigma\", \"\"),\n",
    "    (\"Model 2\", \"k\"),\n",
    "    (\"Model 2\", \"k err\"),\n",
    "    (\"Model 2\", \"rho\"),\n",
    "    (\"Model 2\", \"rho err\"),\n",
    "    (\"Model 2\", \"N0\"),\n",
    "    (\"Model 2\", \"N0 err\"),\n",
    "    (\"Model 4\", \"k\"),\n",
    "    (\"Model 4\", \"k err\"),\n",
    "    (\"Model 4\", \"rho\"),\n",
    "    (\"Model 4\", \"rho err\"),\n",
    "    (\"Model 4\", \"lambda\")\n",
    ")\n",
    "\n",
    "fitting_data = pd.DataFrame(columns=pd.MultiIndex.from_tuples(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is the error on the DA loss computed right now?\n",
    "\n",
    "1. Consider all the radiuses sampled.\n",
    "2. Compute the DA value.\n",
    "3. For every radius sampled, compute the difference from the DA value.\n",
    "4. The absolute value of the average of all these differences is considered as error.\n",
    "\n",
    "(I tried using the Standard Deviation of the radiuses distribution, but it ended up being 10% of the DA itself, so we \"need\" somehow a smaller error estimation)\n",
    "## Loss and Fits -- Uniform Beam Distribution\n",
    "### Loss comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DA0 cutting point\n",
    "DA0 = 26.0\n",
    "\n",
    "# Assign uniform weights to engine and compute loss\n",
    "engine.assign_weights(\n",
    "    sx.assign_uniform_distribution()\n",
    ")\n",
    "real_values = engine.compute_loss(turn_sampling, DA0)\n",
    "\n",
    "# Compute DA-based loss\n",
    "values = uniform_loss(DA, DA0)\n",
    "values = np.concatenate((values, [1.0]))\n",
    "\n",
    "# Error computing\n",
    "values1 = uniform_loss(DA - np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), DA0)\n",
    "values1 = np.concatenate((values1, [1.0]))\n",
    "\n",
    "values2 = uniform_loss(DA + np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), DA0)\n",
    "values2 = np.concatenate((values2, [1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Loss comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6de9dfc7e245c4bbb464e826a48071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Uniform beam (Cutting Point at $DA=26.0$)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(axis_sampling, values, label=\"Values from DA\")\n",
    "ax2.fill_between(axis_sampling, values1, values2, label=\"Values from DA - error\", color=\"C0\", alpha=0.4)\n",
    "ax2.plot(axis_sampling, real_values, label=\"Values from weights\")\n",
    "ax2.legend()\n",
    "ax2.set_xlabel(\"$N$ turns\")\n",
    "ax2.set_ylabel(\"Active beam\")\n",
    "ax2.set_title(\"Uniform beam (Cutting Point at $DA=26.0$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DA from loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_from_loss = DA_from_unifom_loss(real_values, DA0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b216f3eeba54b35884b2a17a5f3c1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison between original DA and DA obtained from real Loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(turn_sampling, DA, label=\"Original DA\")\n",
    "ax3.plot(axis_sampling[:-1], DA_from_loss[:-1], label=\"DA extracted from real loss values\")\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"$DA(N)$\")\n",
    "ax3.set_title(\"Comparison between original DA and DA obtained from real Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare fitting values with Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:55<00:00, 35.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:44<00:00, 45.18it/s]\n"
     ]
    }
   ],
   "source": [
    "k_min = 0.01\n",
    "k_max = 1\n",
    "samples = 2000\n",
    "\n",
    "ks = np.linspace(k_min, k_max, samples)\n",
    "\n",
    "real_pars, real_errs, real_co_pars = explore_k_model_2(turn_sampling, DA, k_min, k_max, samples)\n",
    "loss_pars, loss_errs, loss_co_pars = explore_k_model_2(axis_sampling[:-1], DA_from_loss[:-1], k_min, k_max, samples)\n",
    "\n",
    "real_selected_k_2 = ks[np.argmin(real_errs)]\n",
    "real_selected_pars_2 = real_pars[np.argmin(real_errs)]\n",
    "real_selected_co_pars_2 = real_co_pars[np.argmin(real_errs)]\n",
    "\n",
    "loss_selected_k_2 = ks[np.argmin(loss_errs)]\n",
    "loss_selected_pars_2 = loss_pars[np.argmin(loss_errs)]\n",
    "loss_selected_co_pars_2 = loss_co_pars[np.argmin(loss_errs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL: $\\kappa:$ 0.12044022011005502 , $\\rho_\\ast$ and $N_0$ [36.24834656 46.24748528]\n",
      "FROM LOSS: $\\kappa:$ 0.11598299149574788 , $\\rho_\\ast$ and $N_0$ [36.15994349 63.14581688]\n"
     ]
    }
   ],
   "source": [
    "print(\"REAL:\", \"$\\\\kappa:$\", real_selected_k_2, \", $\\\\rho_\\\\ast$ and $N_0$\", real_selected_pars_2)\n",
    "print(\"FROM LOSS:\", \"$\\\\kappa:$\", loss_selected_k_2, \", $\\\\rho_\\\\ast$ and $N_0$\", loss_selected_pars_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb7580287864b43a02957d64d09af9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison between original DA and DA obtained from real Loss, with Model 2 Fits')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "ax3.plot(turn_sampling, DA, label=\"Original DA\")\n",
    "ax3.plot(turn_sampling, model_2(turn_sampling, real_selected_pars_2[0], real_selected_pars_2[1], real_selected_k_2), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}, N_0={:.4f}$\".format(real_selected_k_2, real_selected_pars_2[0], real_selected_pars_2[1] ))\n",
    "\n",
    "ax3.plot(axis_sampling[:-1], DA_from_loss[:-1], label=\"DA extracted from real loss values\")\n",
    "ax3.plot(turn_sampling, model_2(turn_sampling, loss_selected_pars_2[0], loss_selected_pars_2[1], loss_selected_k_2), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}, N_0={:.4f}$\".format(loss_selected_k_2, loss_selected_pars_2[0], loss_selected_pars_2[1] ))\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"$DA(N)$\")\n",
    "ax3.set_title(\"Comparison between original DA and DA obtained from real Loss, with Model 2 Fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare fitting values with Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:28<00:00, 69.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:19<00:00, 100.48it/s]\n"
     ]
    }
   ],
   "source": [
    "k_min = 0.05\n",
    "k_max = 1\n",
    "samples = 2000\n",
    "\n",
    "ks = np.linspace(k_min, k_max, samples)\n",
    "\n",
    "real_pars, real_errs, real_co_pars = explore_k_model_4(turn_sampling, DA, k_min, k_max, samples)\n",
    "loss_pars, loss_errs, loss_co_pars = explore_k_model_4(axis_sampling[:-1], DA_from_loss[:-1], k_min, k_max, samples)\n",
    "\n",
    "real_selected_k_4 = ks[np.argmin(real_errs)]\n",
    "real_selected_pars_4 = real_pars[np.argmin(real_errs)]\n",
    "real_selected_co_pars_4 = real_co_pars[np.argmin(real_errs)]\n",
    "\n",
    "loss_selected_k_4 = ks[np.argmin(loss_errs)]\n",
    "loss_selected_pars_4 = loss_pars[np.argmin(loss_errs)]\n",
    "loss_selected_co_pars_4 = loss_co_pars[np.argmin(loss_errs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL: $\\kappa:$ 0.21918459229614806 , $\\rho_\\ast$ and $N_0$ [61.0427413]\n",
      "FROM LOSS: $\\kappa:$ 0.21870935467733865 , $\\rho_\\ast$ and $N_0$ [62.42061348]\n"
     ]
    }
   ],
   "source": [
    "print(\"REAL:\", \"$\\\\kappa:$\", real_selected_k_4, \", $\\\\rho_\\\\ast$ and $N_0$\", real_selected_pars_4)\n",
    "print(\"FROM LOSS:\", \"$\\\\kappa:$\", loss_selected_k_4, \", $\\\\rho_\\\\ast$ and $N_0$\", loss_selected_pars_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8669015f46b44e07821088e504d36db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison between original DA and DA obtained from real Loss, with Model 4 Fits $(\\\\lambda=0.5)$')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "ax3.plot(turn_sampling, DA, label=\"Original DA\")\n",
    "ax3.plot(turn_sampling, model_4(turn_sampling, real_selected_pars_4[0], real_selected_k_4), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}$\".format(real_selected_k_4, real_selected_pars_4[0]))\n",
    "\n",
    "ax3.plot(axis_sampling[:-1], DA_from_loss[:-1], label=\"DA extracted from real loss values\")\n",
    "ax3.plot(turn_sampling, model_4(turn_sampling, loss_selected_pars_4[0], loss_selected_k_4), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}$\".format(loss_selected_k_4, loss_selected_pars_4[0]))\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"$DA(N)$\")\n",
    "ax3.set_title(\"Comparison between original DA and DA obtained from real Loss, with Model 4 Fits $(\\\\lambda=0.5)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_data.loc[len(fitting_data)] = [\n",
    "     \"real\",\n",
    "     np.nan,\n",
    "     real_selected_k_2,\n",
    "     ks[1] - ks[0],\n",
    "     real_selected_pars_2[0],\n",
    "     np.sqrt(real_selected_co_pars_2[0, 0]), \n",
    "     real_selected_pars_2[1], \n",
    "     np.sqrt(real_selected_co_pars_2[1, 1]), \n",
    "     real_selected_k_4, \n",
    "     ks[1] - ks[0], \n",
    "     real_selected_pars_4[0], \n",
    "     np.sqrt(real_selected_co_pars_4[0, 0]),\n",
    "     1/2\n",
    "]\n",
    "\n",
    "\n",
    "fitting_data.loc[len(fitting_data)] = [\n",
    "    \"uniform\",\n",
    "     np.nan,\n",
    "     loss_selected_k_2,\n",
    "     ks[1] - ks[0],\n",
    "     loss_selected_pars_2[0],\n",
    "     np.sqrt(loss_selected_co_pars_2[0, 0]),\n",
    "     loss_selected_pars_2[1],\n",
    "     np.sqrt(loss_selected_co_pars_2[1, 1]),\n",
    "     loss_selected_k_4,\n",
    "     ks[1] - ks[0],\n",
    "     loss_selected_pars_4[0],\n",
    "     np.sqrt(loss_selected_co_pars_4[0, 0]),\n",
    "     1/2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Fits -- Symmetric Gaussian Beam Distribution\n",
    "### Choose your Sigma!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DA0 cutting point\n",
    "DA0 = 26.0\n",
    "\n",
    "# Assign uniform weights to engine and compute loss\n",
    "engine.assign_weights(\n",
    "    sx.assign_symmetric_gaussian(sigma)\n",
    ")\n",
    "real_values = engine.compute_loss(turn_sampling, DA0)\n",
    "\n",
    "# Compute DA-based loss\n",
    "values = symmetric_gaussian_loss(DA, sigma, DA0)\n",
    "values = np.concatenate((values, [1.0]))\n",
    "\n",
    "# Error computing\n",
    "values1 = symmetric_gaussian_loss(DA - np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), sigma, DA0)\n",
    "values1 = np.concatenate((values1, [1.0]))\n",
    "\n",
    "values2 = symmetric_gaussian_loss(DA + np.absolute(np.mean(radiuses - DA, axis=(0,1,2))), sigma, DA0)\n",
    "values2 = np.concatenate((values2, [1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Loss comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049ed3ca0c0b4072adddeb3b161097f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Symmetric Gaussian beam ($\\\\sigma=15.0$, Cutting Point at $DA=26.0$)')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(axis_sampling, values, label=\"Values from DA\")\n",
    "ax2.fill_between(axis_sampling, values1, values2, label=\"Values from DA - error\", color=\"C0\", alpha=0.4)\n",
    "ax2.plot(axis_sampling, real_values, label=\"Values from weights\")\n",
    "ax2.legend()\n",
    "ax2.set_xlabel(\"$N$ turns\")\n",
    "ax2.set_ylabel(\"Active beam\")\n",
    "ax2.set_title(\"Symmetric Gaussian beam ($\\\\sigma={}$, Cutting Point at $DA=26.0$)\".format(sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DA from loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_from_loss = DA_from_symmetric_gaussian_loss(real_values, sigma, DA0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299f4362be8443e58409c03a09cf43c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison between original DA and DA obtained from real Loss')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(turn_sampling, DA, label=\"Original DA\")\n",
    "ax3.plot(axis_sampling[:-1], DA_from_loss[:-1], label=\"DA extracted from real loss values\")\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"$DA(N)$\")\n",
    "ax3.set_title(\"Comparison between original DA and DA obtained from real Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare fitting values with Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:56<00:00, 35.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:50<00:00, 39.77it/s]\n"
     ]
    }
   ],
   "source": [
    "k_min = 0.01\n",
    "k_max = 1\n",
    "samples = 2000\n",
    "\n",
    "ks = np.linspace(k_min, k_max, samples)\n",
    "\n",
    "real_pars, real_errs, real_co_pars = explore_k_model_2(turn_sampling, DA, k_min, k_max, samples)\n",
    "loss_pars, loss_errs, loss_co_pars = explore_k_model_2(axis_sampling[:-1], DA_from_loss[:-1], k_min, k_max, samples)\n",
    "\n",
    "real_selected_k_2 = ks[np.argmin(real_errs)]\n",
    "real_selected_pars_2 = real_pars[np.argmin(real_errs)]\n",
    "real_selected_co_pars_2 = real_co_pars[np.argmin(real_errs)]\n",
    "\n",
    "loss_selected_k_2 = ks[np.argmin(loss_errs)]\n",
    "loss_selected_pars_2 = loss_pars[np.argmin(loss_errs)]\n",
    "loss_selected_co_pars_2 = loss_co_pars[np.argmin(loss_errs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL: $\\kappa:$ 0.12044022011005502 , $\\rho_\\ast$ and $N_0$ [36.24834656 46.24748528]\n",
      "FROM LOSS: $\\kappa:$ 0.11994497248624313 , $\\rho_\\ast$ and $N_0$ [36.39737958 53.14201819]\n"
     ]
    }
   ],
   "source": [
    "print(\"REAL:\", \"$\\\\kappa:$\", real_selected_k_2, \", $\\\\rho_\\\\ast$ and $N_0$\", real_selected_pars_2)\n",
    "print(\"FROM LOSS:\", \"$\\\\kappa:$\", loss_selected_k_2, \", $\\\\rho_\\\\ast$ and $N_0$\", loss_selected_pars_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c3bee90940424c81d22591ee8074be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison between original DA and DA obtained from real Loss, with Model 2 Fits')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "ax3.plot(turn_sampling, DA, label=\"Original DA\")\n",
    "ax3.plot(turn_sampling, model_2(turn_sampling, real_selected_pars_2[0], real_selected_pars_2[1], real_selected_k_2), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}, N_0={:.4f}$\".format(real_selected_k_2, real_selected_pars_2[0], real_selected_pars_2[1] ))\n",
    "\n",
    "ax3.plot(axis_sampling[:-1], DA_from_loss[:-1], label=\"DA extracted from real loss values\")\n",
    "ax3.plot(turn_sampling, model_2(turn_sampling, loss_selected_pars_2[0], loss_selected_pars_2[1], loss_selected_k_2), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}, N_0={:.4f}$\".format(loss_selected_k_2, loss_selected_pars_2[0], loss_selected_pars_2[1] ))\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"$DA(N)$\")\n",
    "ax3.set_title(\"Comparison between original DA and DA obtained from real Loss, with Model 2 Fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare fitting values with Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:20<00:00, 98.14it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:19<00:00, 103.45it/s]\n"
     ]
    }
   ],
   "source": [
    "k_min = 0.05\n",
    "k_max = 1\n",
    "samples = 2000\n",
    "\n",
    "ks = np.linspace(k_min, k_max, samples)\n",
    "\n",
    "real_pars, real_errs, real_co_pars = explore_k_model_4(turn_sampling, DA, k_min, k_max, samples)\n",
    "loss_pars, loss_errs, loss_co_pars = explore_k_model_4(axis_sampling[:-1], DA_from_loss[:-1], k_min, k_max, samples)\n",
    "\n",
    "real_selected_k_4 = ks[np.argmin(real_errs)]\n",
    "real_selected_pars_4 = real_pars[np.argmin(real_errs)]\n",
    "real_selected_co_pars_4 = real_co_pars[np.argmin(real_errs)]\n",
    "\n",
    "loss_selected_k_4 = ks[np.argmin(loss_errs)]\n",
    "loss_selected_pars_4 = loss_pars[np.argmin(loss_errs)]\n",
    "loss_selected_co_pars_4 = loss_co_pars[np.argmin(loss_errs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL: $\\kappa:$ 0.21918459229614806 , $\\rho_\\ast$ and $N_0$ [61.0427413]\n",
      "FROM LOSS: $\\kappa:$ 0.21870935467733865 , $\\rho_\\ast$ and $N_0$ [61.48242142]\n"
     ]
    }
   ],
   "source": [
    "print(\"REAL:\", \"$\\\\kappa:$\", real_selected_k_4, \", $\\\\rho_\\\\ast$ and $N_0$\", real_selected_pars_4)\n",
    "print(\"FROM LOSS:\", \"$\\\\kappa:$\", loss_selected_k_4, \", $\\\\rho_\\\\ast$ and $N_0$\", loss_selected_pars_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ae17682b584d1c9b3b8de81f755c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison between original DA and DA obtained from real Loss, with Model 4 Fits $(\\\\lambda=0.5)$')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "ax3.plot(turn_sampling, DA, label=\"Original DA\")\n",
    "ax3.plot(turn_sampling, model_4(turn_sampling, real_selected_pars_4[0], real_selected_k_4), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}$\".format(real_selected_k_4, real_selected_pars_4[0]))\n",
    "\n",
    "ax3.plot(axis_sampling[:-1], DA_from_loss[:-1], label=\"DA extracted from real loss values\")\n",
    "ax3.plot(turn_sampling, model_4(turn_sampling, loss_selected_pars_4[0], loss_selected_k_4), label=\"Fitting on original DA\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}$\".format(loss_selected_k_4, loss_selected_pars_4[0]))\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(\"$N$ turns\")\n",
    "ax3.set_ylabel(\"$DA(N)$\")\n",
    "ax3.set_title(\"Comparison between original DA and DA obtained from real Loss, with Model 4 Fits $(\\\\lambda=0.5)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_data.loc[len(fitting_data)] = [\n",
    "    \"gaussian\",\n",
    "     sigma,\n",
    "     loss_selected_k_2,\n",
    "     ks[1] - ks[0],\n",
    "     loss_selected_pars_2[0],\n",
    "     np.sqrt(loss_selected_co_pars_2[0, 0]),\n",
    "     loss_selected_pars_2[1],\n",
    "     np.sqrt(loss_selected_co_pars_2[1, 1]),\n",
    "     loss_selected_k_4,\n",
    "     ks[1] - ks[0],\n",
    "     loss_selected_pars_4[0],\n",
    "     np.sqrt(loss_selected_co_pars_4[0, 0]),\n",
    "     1/2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display general dataframe with fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sigma</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Model 2</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Model 4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>k err</th>\n",
       "      <th>rho</th>\n",
       "      <th>rho err</th>\n",
       "      <th>N0</th>\n",
       "      <th>N0 err</th>\n",
       "      <th>k</th>\n",
       "      <th>k err</th>\n",
       "      <th>rho</th>\n",
       "      <th>rho err</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120440</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>36.248347</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>46.247485</td>\n",
       "      <td>0.202349</td>\n",
       "      <td>0.219185</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>61.042741</td>\n",
       "      <td>0.012779</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115983</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>36.159943</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>63.145817</td>\n",
       "      <td>0.567224</td>\n",
       "      <td>0.218709</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>62.420613</td>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaussian</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.119945</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>36.397380</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>53.142018</td>\n",
       "      <td>0.524095</td>\n",
       "      <td>0.218709</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>61.482421</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type sigma   Model 2                                            \\\n",
       "                          k     k err        rho   rho err         N0   \n",
       "0      real   NaN  0.120440  0.000475  36.248347  0.003771  46.247485   \n",
       "1   uniform   NaN  0.115983  0.000475  36.159943  0.008910  63.145817   \n",
       "2  gaussian  15.0  0.119945  0.000475  36.397380  0.009060  53.142018   \n",
       "\n",
       "              Model 4                                        \n",
       "     N0 err         k     k err        rho   rho err lambda  \n",
       "0  0.202349  0.219185  0.000475  61.042741  0.012779    0.5  \n",
       "1  0.567224  0.218709  0.000475  62.420613  0.021589    0.5  \n",
       "2  0.524095  0.218709  0.000475  61.482421  0.018352    0.5  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
